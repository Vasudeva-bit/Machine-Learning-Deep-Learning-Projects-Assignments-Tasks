{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot-Coding_Ninjas_LPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpg4RphTNtHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50105b46-1a1f-4186-ff90-0de1558c4afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chatterbot in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: mathparse<0.2,>=0.1 in /usr/local/lib/python3.7/dist-packages (from chatterbot) (0.1.2)\n",
            "Requirement already satisfied: sqlalchemy<1.4,>=1.3 in /usr/local/lib/python3.7/dist-packages (from chatterbot) (1.3.24)\n",
            "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from chatterbot) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from chatterbot) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<2.9,>=2.8->chatterbot) (1.15.0)\n",
            "Requirement already satisfied: chatterbot_corpus in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: PyYAML<4.0,>=3.12 in /usr/local/lib/python3.7/dist-packages (from chatterbot_corpus) (3.13)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "!pip install chatterbot\n",
        "!pip install chatterbot_corpus\n",
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "botname = 'Norman'\n",
        "chatbot = ChatBot(botname)\n",
        "\n",
        "chatbot = ChatBot(botname, \n",
        "\t#storage_adapter='chatterbot.storage.SQLStorageAdapter',\n",
        "\tlogic_adapters=[\n",
        "        {\n",
        "            'import_path': 'chatterbot.logic.BestMatch',\n",
        "            'default_response': 'None',\n",
        "            'maximum_similarity_threshold': 0.8 # tune this threshold\n",
        "        },\n",
        "        {\n",
        "            \"import_path\": \"chatterbot.logic.MathematicalEvaluation\",\n",
        "\n",
        "        },\n",
        "        # {\n",
        "        #     \"import_path\": \"chatterbot.logic.UnitConversion\",\n",
        "\n",
        "        # },\n",
        "        # {\n",
        "        #     \"import_path\": \"profanity_adapter.ProfanityAdapter\",\n",
        "\n",
        "        # },\n",
        "        # {\n",
        "        #     \"import_path\": \"covid19_adapter.Covid19Adapter\",\n",
        "\n",
        "        # },\n",
        "    ],\n",
        " )"
      ],
      "metadata": {
        "id": "9G99Czzf3FHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training list data for question answers properly\n",
        "# from chatterbot.trainers import ListTrainer\n",
        "\n",
        "# trainer = ListTrainer(bot)\n",
        "\n",
        "# trainer.train([\n",
        "#     'How are you?',\n",
        "#     'I am good.',\n",
        "#     'That is good to hear.',\n",
        "#     'Thank you',\n",
        "#     'You are welcome.',\n",
        "# ]"
      ],
      "metadata": {
        "id": "hkRpzWsshASG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = ChatterBotCorpusTrainer(chatbot)\n",
        "\n",
        "# trainer.train(\n",
        "#     str(pathlib.Path().absolute())+'/english/',\n",
        "# )\n",
        "\n",
        "trainer = ChatterBotCorpusTrainer(chatbot)\n",
        "\n",
        "trainer.train(\n",
        "    \"chatterbot.corpus.english\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrfJe2C5Fc25",
        "outputId": "32db6b82-1452-49f3-dbb6-31d83914eec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ai.yml: [####################] 100%\n",
            "Training botprofile.yml: [####################] 100%\n",
            "Training computers.yml: [####################] 100%\n",
            "Training conversations.yml: [####################] 100%\n",
            "Training emotion.yml: [####################] 100%\n",
            "Training food.yml: [####################] 100%\n",
            "Training gossip.yml: [####################] 100%\n",
            "Training greetings.yml: [####################] 100%\n",
            "Training health.yml: [####################] 100%\n",
            "Training history.yml: [####################] 100%\n",
            "Training humor.yml: [####################] 100%\n",
            "Training literature.yml: [####################] 100%\n",
            "Training money.yml: [####################] 100%\n",
            "Training movies.yml: [####################] 100%\n",
            "Training politics.yml: [####################] 100%\n",
            "Training psychology.yml: [####################] 100%\n",
            "Training science.yml: [####################] 100%\n",
            "Training sports.yml: [####################] 100%\n",
            "Training trivia.yml: [####################] 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('corpus.txt', errors='strict')\n",
        "data = f.read()\n",
        "data = data.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "sent_tokens = nltk.sent_tokenize(data)\n",
        "word_tokens = nltk.word_tokenize(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orR_iGfShjz7",
        "outputId": "47ab75c9-a2f3-439d-8268-8c3a297a232f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXkPmBARjZGS",
        "outputId": "6bbbf36d-6f91-407c-8e17-b9e298baf344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['at coding ninjas, our mission is to continuously innovate the best ways to train the next generation of developers and to transform the the way tech education is delivered.',\n",
              " 'coding ninjas was founded in 2016 to bridge the knowledge gap between colleges and industry.',\n",
              " 'founded by ankush singla, kannu mittal and dhawal parate, coding ninjas boasts of world-class teaching faculty and a state-of-art learning platform for coding education with faculty alumni of iit, stanford, iiit and facebook.']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLZNK9XdkL-A",
        "outputId": "c9403f6b-acb3-4bc1-a0f5-51d1b4cdcded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['at', 'coding', 'ninjas']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict= dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "yxNIywjikPJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Response Generation"
      ],
      "metadata": {
        "id": "JhwC-63LnUcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "3t6SJJq9mKSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refer_chat(user_input):\n",
        "  robo1_response = ''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words='english')\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if (req_tfidf == 0):\n",
        "    robo1_response= robo1_response+\"I could not answer this right now but you can contact the head of our dept.\" # add the dept recommendation engine and contact details\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response+sent_tokens[idx]\n",
        "    return robo1_response"
      ],
      "metadata": {
        "id": "WNRTUv5goIhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining start and end of chat"
      ],
      "metadata": {
        "id": "TC4RQKExrO_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greet_input = ('hi', 'hello', 'hey', 'sup', 'whats up', 'hai')\n",
        "greet_response = ('hello', 'nods', 'welcome', 'thanks for chosing me', 'glab atleast you are talking to me')\n",
        "def greet(user_input):\n",
        "  for word in user_input.split():\n",
        "    if word.lower() in greet_input:\n",
        "      return random.choice(greet_response)"
      ],
      "metadata": {
        "id": "YknjOnPEu9uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def message_probability(user_message, recognised_words, single_response=False, required_words=[]):\n",
        "    message_certainty = 0\n",
        "    has_required_words = True\n",
        "\n",
        "    # Counts how many words are present in each predefined message\n",
        "    for word in user_message:\n",
        "        if word in recognised_words:\n",
        "            message_certainty += 1\n",
        "\n",
        "    # Calculates the percent of recognised words in a user message\n",
        "    percentage = float(message_certainty) / float(len(recognised_words))\n",
        "\n",
        "    # Checks that the required words are in the string\n",
        "    for word in required_words:\n",
        "        if word not in user_message:\n",
        "            has_required_words = False\n",
        "            break\n",
        "\n",
        "    # Must either have the required words, or be a single response\n",
        "    if has_required_words or single_response:\n",
        "        return int(percentage * 100)\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "M-UjoiAN4FyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_all_messages(message):\n",
        "    highest_prob_list = {}\n",
        "\n",
        "    # Simplifies response creation / adds it to the dict\n",
        "    def response(bot_response, list_of_words, single_response=False, required_words=[]):\n",
        "        nonlocal highest_prob_list\n",
        "        highest_prob_list[bot_response] = message_probability(message, list_of_words, single_response, required_words)\n",
        "\n",
        "    # Responses -------------------------------------------------------------------------------------------------------\n",
        "    response('Hello!', ['hello', 'hi', 'hey', 'sup', 'heyo'], single_response=True)\n",
        "    response('See you!', ['bye', 'goodbye'], single_response=True)\n",
        "    response('I\\'m doing fine, and you?', ['how', 'are', 'you', 'doing'], required_words=['how'])\n",
        "    response('ask more!', ['good', 'am', 'I', 'fine', 'nice', 'ok', 'okay', 'kk'], single_response=True)\n",
        "    response('Me too! then?', ['i', 'love', 'coding', 'ninjas', 'lpu'], required_words=['love'])\n",
        "\n",
        "    best_match = max(highest_prob_list, key=highest_prob_list.get)\n",
        "    # print(highest_prob_list)\n",
        "    # print(f'Best match = {best_match} | Score: {highest_prob_list[best_match]}')\n",
        "\n",
        "    return None if highest_prob_list[best_match] < 1 else best_match\n"
      ],
      "metadata": {
        "id": "tCE0i1Y-2eeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "print('BOT: My name is ninja_assitant, Lets have a conversation, I am hear to help you with any question, doubt, details etc. Anytime, if you would like to quit just say bye!!')\n",
        "while (flag):\n",
        "  user_input = input()\n",
        "  user_input = user_input.lower()# re.split(r'\\s+|[,;?!.-]\\s*', user_input.lower())\n",
        "  if (user_input != 'bye'):\n",
        "    if (user_input == 'Thanks' or user_input =='Thank you' or user_input == 'Tnx' or user_input =='Thankq' or user_input == 'Tq'):\n",
        "      flag = False\n",
        "      print('BOT: Thank you, nice talking to you')\n",
        "    else:\n",
        "      if (greet(user_input)!=None):\n",
        "        print('BOT: '+greet(user_input))\n",
        "      elif check_all_messages(user_input.split()) !=None:\n",
        "        print('BOT: '+check_all_messages(user_input.split()))\n",
        "      elif str(chatbot.get_response(user_input))!= 'None':\n",
        "        print('BOT: '+str(chatbot.get_response(user_input)))\n",
        "      else:\n",
        "        sent_tokens.append(user_input)\n",
        "        word_tokens = word_tokens + nltk.word_tokenize(user_input)\n",
        "        final = list(set(word_tokens))\n",
        "        print('BOT: ', end='')\n",
        "        print(refer_chat(user_input))\n",
        "        sent_tokens.remove(user_input)\n",
        "  else:\n",
        "    flag = False\n",
        "    print('BOT: Good bye, visit again')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWB9wFHUrL8P",
        "outputId": "89be2a90-3b59-4b81-cd60-960f0eda391e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: My name is ninja_assitant, Lets have a conversation, I am hear to help you with any question, doubt, details etc. Anytime, if you would like to quit just say bye!!\n",
            "hi\n",
            "BOT: glab atleast you are talking to me\n",
            "how r u\n",
            "BOT: I'm doing fine, and you?\n",
            "founded year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: coding ninjas was founded in 2016 to bridge the knowledge gap between colleges and industry.\n",
            "alumni\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: today, coding ninjas ecosystem comprises of 40,000+ students and alumni, 1000+ campus ambassadors, 2000+ teaching assistants, and 150+ employees.\n",
            "what is spiderman\n",
            "BOT: a comic book story made into a movie.\n",
            "bye\n",
            "BOT: Good bye, visit again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To-do\n",
        "1. options of topics\n",
        "2. statics response types\n",
        "3. nltk response types\n",
        "4. data for various sections and use grammerly\n",
        "5. contact dept head or our team.\n",
        "6. interactive sentances to make a feel of bot as amazing as alexa or siri by having sentances like \"I was an avg student to answer so leave a message to the cleverest of our team i.e., name in random again for dept heads\"\n",
        "7. how to integrate bot and website ? some one can join me who has experience on stuff like this i.e., we get widget for free and input on website is taken on to this python file and then use that to generate and display response of the bot to chat screen.\n",
        "\n",
        "Help:\n",
        "1. data collection help on diff sections with grammerly.\n",
        "2. a skilled one to help me integrate in some random web page and integrate to whole website after testing."
      ],
      "metadata": {
        "id": "8DaPLC0KLQHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4fT23ijZaaW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}